---
title: "607 Project 3"
author: "Katherine Evers"
date: "3/18/2019"
output: html_document
---

```{r results='hide', message=FALSE, warning=FALSE}
library("tidyverse")  
library("rvest")    
library("stringi")   
library("xml2")
library("kableExtra")
```

########################################################Old code#####################################################
```{r}
#Import url
url <- "https://www.indeed.com/jobs?q=%22data%20scientist%22&l=Silicon%20Valley%2C%20CA"
#read url
page <- read_html(url)

#Extract job titles
jobTitle <- page %>% 
  html_nodes("div") %>%
  html_nodes(xpath = '//a[@data-tn-element = "jobTitle"]') %>%
  html_attr("title")

#Extract company names
companyName <- page %>% 
  html_nodes("span")  %>% 
  html_nodes(xpath = '//*[@class="company"]')  %>% 
  html_text() %>%
  stri_trim_both() -> company.name 

#Extract job posting links  
links <- page %>% 
  html_nodes("div") %>%
  html_nodes(xpath = '//*[@data-tn-element="jobTitle"]') %>%
  html_attr("href")

#Extract job descriptions  
jobDescription <- c()
for(i in seq_along(links)) {
  url <- paste0("https://indeed.com/", links[i])
  page <- read_html(url)
  jobDescription[[i]] <- page %>%
    html_nodes("span")  %>% 
    html_nodes(xpath = '//*[@class="jobsearch-JobComponent-description icl-u-xs-mt--md"]') %>% 
    html_text() %>%
    stri_trim_both()
}

#######################################################New code#######################################################
```{r}
url <- "https://www.indeed.com/jobs?q=data+scientist&jt=fulltime"
page <- read_html(url)

# location urls
location <- page %>% 
  html_nodes("li") %>%
  html_nodes(xpath = '//*[@rel="nofollow"]') %>%
  html_attr("href")

#Extract top 5 locations based on indexes
location2 <- location[c(9:13)] 


pageStart <- 10 # starting page 
pageEnd <- 20 # last page results
pageResults <- seq(from = pageStart, to = pageEnd, by = 10)
 
fullDf <- data.frame()
url<-c()
for(j in 1:5) {
  
  baseUrl <- "https://www.indeed.com"
  url1 <- paste(baseUrl, location2[j], sep="")
  
  for(i in seq_along(pageResults)) {
    url2 <- paste0(url1, "&start=", pageResults[i])
    
    url<-rbind(url, url2)
  }}

for(i in 1:9) {
  url <- url[i]
  page <- read_html(url)

  #Extract job titles
  jobTitle <- page %>% 
    html_nodes("div") %>%
    html_nodes(xpath = '//*[@data-tn-element="jobTitle"]') %>%
    html_attr("title")
    
  #Extract company names
  companyName <- page %>% 
    html_nodes("span")  %>% 
    html_nodes(xpath = '//*[@class="company"]')  %>% 
    html_text() %>%
    stri_trim_both() -> company.name 
  
  #Extract job locations
  jobLocation <- page %>% 
    html_nodes("span") %>% 
    html_nodes(xpath = '//*[@class="location"]')%>% 
    html_text() %>%
    stri_trim_both() -> job.location
    
  #get the short sumary
  jobSummary <- page %>% 
    html_nodes("span")  %>% 
    html_nodes(xpath = '//*[@class="summary"]')  %>% 
    html_text() %>%
    stri_trim_both() -> summary.short 
    
    df <- data.frame(jobTitle, companyName, jobLocation, jobSummary)
  fullDf <- rbind(fullDf, df)
} #Error: 'NA' does not exist in current working directory

DT::datatable(fullDf, editable = TRUE)
```

  
#Create dataframe (NOTE: stringsasfactors is false here)
df <- data.frame(jobTitle, companyName, jobDescription, stringsAsFactors = FALSE)

DT::datatable(df, editable = TRUE)

#tidytext code
jobcorpus_tb<-tibble(eachjob = seq_along(df$jobDescription), text = df$jobDescription)


jobcorpus_tb %>%
  unnest_tokens(word, text)  %>% 
  anti_join(stop_words) %>% 
  group_by(word) %>%
  count(sort = TRUE) %>%
  ungroup() %>%
  top_n(20) %>%
  ggplot(aes(x = fct_reorder(word, n), y = n)) +
  geom_bar(stat = "identity", width = 0.5) + 
  xlab(NULL) +
  coord_flip() +
  ylab("Word Frequency") +
  ggtitle("Most Common Corpus Words") +
  theme(legend.position = "none")
```
